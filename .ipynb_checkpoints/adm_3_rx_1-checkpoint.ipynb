{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f92268ab-5062-480a-bfdb-d0446a68b538",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28ccdb0c-3aa9-49c4-b292-772d6e220de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import polars as pl\n",
    "import gc\n",
    "import numpy as np\n",
    "pl.enable_string_cache() #disable_string_cache() for opposite effect.\n",
    "\n",
    "import s3fs\n",
    "import boto3\n",
    "from io import BytesIO as bo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5c2bcf-8eca-4197-ac85-b3de54d02e5d",
   "metadata": {},
   "source": [
    "Calculate Date Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b88d629-cb63-4d6a-844d-1b1c2fa88827",
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables -\n",
    "this_day = datetime.today()\n",
    "# ### FOR TESTING - REMOVE LATER ### \n",
    "# this_day = this_day - timedelta(days=7)\n",
    "# ####\n",
    "days_to_monday = (this_day.weekday() - 0) % 7\n",
    "monday = this_day - timedelta(days=days_to_monday)\n",
    "\n",
    "CUR_PROC_WK = monday.strftime(\"%Y%m%d\")\n",
    "\n",
    "PRE_PROC_WK0 = monday - timedelta(days=7)\n",
    "PRE_PROC_WK = str(PRE_PROC_WK0.year) + str(PRE_PROC_WK0.month).zfill(2) + str(PRE_PROC_WK0.day).zfill(2)\n",
    "\n",
    "CUR_WK0 = monday - timedelta(days=17)\n",
    "CUR_WK = str(CUR_WK0.year) + str(CUR_WK0.month).zfill(2) + str(CUR_WK0.day).zfill(2)\n",
    "\n",
    "PRE_WK0 = monday - timedelta(days=24)\n",
    "PRE_WK = PRE_WK0.strftime(\"%Y%m%d\")\n",
    "\n",
    "MONTH_OFF = CUR_WK0.replace(day=1).date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fc46a6f-a97b-4a24-9d4b-d8b192aac3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing IW Release File \n",
    "s3 = s3fs.S3FileSystem()\n",
    "bucket_list = s3.listdir(f'vortex-staging-a65ced90/PYADM/raw/{CUR_PROC_WK}/inbound/')\n",
    "for file in bucket_list:\n",
    "    if (file['Key'].__contains__(f\"IRWD_RELEASE_WKLY_{CUR_PROC_WK}\")):\n",
    "        release_file = file['Key']\n",
    "\n",
    "# Reading Release File -\n",
    "s3_client = boto3.client('s3')\n",
    "bucket = release_file.split('/')[0]\n",
    "file_key = release_file.split('/',1)[1]\n",
    "\n",
    "adm = pd.read_csv(f's3://{bucket}/{file_key}',sep='|')\n",
    "adm1 = adm[CUR_PROC_WK].tolist()\n",
    "\n",
    "for item in adm1:\n",
    "    if item.startswith('P_OUT_110_IRWD_PERIOD_'):\n",
    "        PERIOD_TIMESTAMP = item.split('_')[-1].split('.')[0]\n",
    "    elif item.startswith('P_OUT_110_IRWD_WKLY_RX_'):\n",
    "        RX_TIMESTAMP = item.split('_')[-1].split('.')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8f361c-56f4-417f-ab2a-6faf08fab9c7",
   "metadata": {},
   "source": [
    "Library Names and File Paths :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60247a30-c7c7-4a77-bd5b-fb3a13336b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_path = f'PYADM/raw/{CUR_PROC_WK}/inbound/'\n",
    "curwk = f'PYADM/raw/{CUR_PROC_WK}/dataframes/'\n",
    "prewk = f'PYADM/raw/{PRE_PROC_WK}/dataframes/'\n",
    "wkxpn = 'PYADM/weekly/staging/xponent/'\n",
    "mthxpn = 'PYADM/monthly/staging/xponent/'\n",
    "pwkxpn = f'PYADM/weekly/archive/{PRE_WK}/xponent/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3f5b385-fc3c-4541-8cbc-5f99056e289c",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_PERIOD_CUR_WK = pd.read_csv(\n",
    "    f's3://{bucket}/{raw_path}P_OUT_110_IRWD_PERIOD_{PERIOD_TIMESTAMP}.TXT',\n",
    "    delimiter='|',parse_dates=[0,1,3,5]\n",
    ")\n",
    "\n",
    "curwk_PERIOD_CUR_WK_v0 = temp_PERIOD_CUR_WK.set_index('PERIOD_KEY',verify_integrity = True) #creates index on priod key (unsure why)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1ee0c56-fc4a-415d-9229-52e524ac897b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WEEKLY PARAMETER\n",
    "\n",
    "temp_RX_PERIOD_TIMESORT = (curwk_PERIOD_CUR_WK_v0['WK_END_DATE'].copy()).to_frame().reset_index(drop=True)\n",
    "temp_RX_PERIOD_TIMESORT.drop_duplicates(subset = ['WK_END_DATE'],inplace = True)\n",
    "temp_RX_PERIOD_TIMESORT.sort_values(by = 'WK_END_DATE',inplace = True,ignore_index=True)\n",
    "\n",
    "W = temp_RX_PERIOD_TIMESORT['WK_END_DATE'].max()\n",
    "data = [{'I':i,'WK_END_DATE': W - pd.DateOffset(weeks=i-1)} for i in range(1, 106)]\n",
    "curwk_DATE_PARM_WK = pd.DataFrame(data)\n",
    "#curwk_DATE_PARM_WK['WK_END_DATE'] = curwk_DATE_PARM_WK['WK_END_DATE'].dt.strftime(\"%Y%m%d\")\n",
    "\n",
    "# in sas we did i-1  + 5 for some reason, added I as a column, convereted WK_END_DATE to str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e03125ab-eeb9-4419-8c58-6fd116c48025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MONTHLY PARAMETER \n",
    "temp_RX_PERIOD_MTHSORT = (curwk_PERIOD_CUR_WK_v0['CAL_MONTH'].copy()).to_frame().reset_index(drop=True)\n",
    "temp_RX_PERIOD_MTHSORT.drop_duplicates(subset = ['CAL_MONTH'],inplace = True)\n",
    "temp_RX_PERIOD_MTHSORT.sort_values(by = 'CAL_MONTH',inplace = True,ignore_index=True)\n",
    "\n",
    "month_end_date = CUR_WK0.replace(day=1) - timedelta(days=1)\n",
    "if 0 <= (CUR_WK0 - month_end_date).days < 7: # When its Month Ending (we use MONTH OFF to start subtracting)\n",
    "    MT = MONTH_OFF - pd.DateOffset(days = 1)\n",
    "else:                                        # When its not month ending we take max date from CAL_MONTH value from file\n",
    "    MT = temp_RX_PERIOD_MTHSORT['CAL_MONTH'].max()\n",
    "\n",
    "data = [{'I':i,'CCYYMM':MT - pd.DateOffset(months=i-1),'DATE_AS_OF':W} for i in range(1,25)]\n",
    "curwk_DATE_PARM_MTH = pd.DataFrame(data)\n",
    "#will need to truncate date to show YYYYMM or a string ?\n",
    "curwk_DATE_PARM_MTH['CCYYMM'] = curwk_DATE_PARM_MTH['CCYYMM'].dt.strftime(\"%Y%m\") #Comment this if not needed\n",
    "temp_PERIOD_CUR_WK.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "399e4159-a9d2-48bc-9a8c-3cc4f6f1db01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store Datasets as required\n",
    "# sdap(curwk,curwk_DATE_PARM_WK)\n",
    "# sdap(curwk,curwk_DATE_PARM_MTH)\n",
    "\n",
    "curwk_DATE_PARM_WK.to_parquet(f's3://{bucket}/{curwk}curwk_DATE_PARM_WK.parquet')\n",
    "curwk_DATE_PARM_MTH.to_parquet(f's3://{bucket}/{curwk}curwk_DATE_PARM_MTH.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7897e266-b5e8-4601-b565-b44063d2380e",
   "metadata": {},
   "source": [
    "### 5 - RX Delta - input feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6574a819-2507-41e5-a658-6d70de4c9449",
   "metadata": {},
   "outputs": [],
   "source": [
    "curwk_RAW_RX_CUR_WK = pd.read_csv(\n",
    "    f's3://{bucket}/{raw_path}P_OUT_110_IRWD_WKLY_RX_{RX_TIMESTAMP}.TXT',\n",
    "    delimiter='|',dtype={7:str}\n",
    ")\n",
    "curwk_RAW_RX_CUR_WK['MKT_CD'] = curwk_RAW_RX_CUR_WK['MarketName'].str.slice(0, 3)\n",
    "\n",
    "curwk_RAW_RX_CUR_WK.sort_values(by='PeriodKey',ignore_index=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "331d57c1-3532-465b-8520-e06dd29e02ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Added this step to trim weekly delta data for restatements older than 105 weeks.\n",
    "threshold_105 = curwk_DATE_PARM_WK['WK_END_DATE'].min().strftime('%Y%m%d')\n",
    "curwk_RAW_RX_CUR_WK = curwk_RAW_RX_CUR_WK[curwk_RAW_RX_CUR_WK['PeriodKey'] >= threshold_105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd9362fc-0d53-4e67-9b75-2f11f66add8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.1: Check the period key to see if there is any restatement and missing value\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PeriodKey</th>\n",
       "      <th>FREQUENCY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20220513</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20220520</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20220527</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20220603</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20220610</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>20240419</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>20240426</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>20240430</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>20240503</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>20240510</td>\n",
       "      <td>224535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    PeriodKey  FREQUENCY\n",
       "0    20220513         10\n",
       "1    20220520         12\n",
       "2    20220527          4\n",
       "3    20220603          2\n",
       "4    20220610         17\n",
       "..        ...        ...\n",
       "117  20240419         33\n",
       "118  20240426         18\n",
       "119  20240430          5\n",
       "120  20240503          9\n",
       "121  20240510     224535\n",
       "\n",
       "[122 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"5.1: Check the period key to see if there is any restatement and missing value\")\n",
    "frequency_table = curwk_RAW_RX_CUR_WK.groupby(['PeriodKey']).size().reset_index(name='FREQUENCY')\n",
    "frequency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ab55366-15b2-4e97-8253-7c77f5f9e479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.2: Check the MKT_CD to see if there is new market and missing value\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MKT_CD</th>\n",
       "      <th>FREQUENCY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LAX</td>\n",
       "      <td>226062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  MKT_CD  FREQUENCY\n",
       "0    LAX     226062"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"5.2: Check the MKT_CD to see if there is new market and missing value\")\n",
    "frequency_table = curwk_RAW_RX_CUR_WK.groupby(['MKT_CD']).size().reset_index(name='FREQUENCY')\n",
    "frequency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ec68080-614f-4763-8fac-8f1ab1cb6405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This should always be 0 :  0\n"
     ]
    }
   ],
   "source": [
    "#APPLY MERGE CASES  \n",
    "#rdap(curwk,'curwk_MERGES')\n",
    "curwk_MERGES = pd.read_parquet(f's3://{bucket}/{curwk}curwk_MERGES.parquet')\n",
    "temp_MERGECASES = curwk_MERGES[['IID','IronwoodWinnerID','IronwoodLoserID']].copy()\n",
    "temp_MERGECASES.drop_duplicates(subset='IID',inplace=True)\n",
    "temp_MERGECASES.sort_values(by='IID',ignore_index=True,inplace=True)\n",
    "mask = (temp_MERGECASES['IID'] == temp_MERGECASES['IronwoodWinnerID'])\n",
    "fdf = temp_MERGECASES[mask]\n",
    "print(\"This should always be 0 : \",fdf.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2711c12-96b5-4271-b09f-d530646f3798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.3: Check If merge case is valid, List of two loser iid are merged to one winner : \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IID</th>\n",
       "      <th>IronwoodWinnerID</th>\n",
       "      <th>IronwoodLoserID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12818512</td>\n",
       "      <td>278454</td>\n",
       "      <td>12818512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1534124</td>\n",
       "      <td>278454</td>\n",
       "      <td>1534124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1917104</td>\n",
       "      <td>2524548</td>\n",
       "      <td>1917104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13230484</td>\n",
       "      <td>2524548</td>\n",
       "      <td>13230484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13524672</td>\n",
       "      <td>2726667</td>\n",
       "      <td>13524672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        IID  IronwoodWinnerID  IronwoodLoserID\n",
       "0  12818512            278454         12818512\n",
       "1   1534124            278454          1534124\n",
       "2   1917104           2524548          1917104\n",
       "3  13230484           2524548         13230484\n",
       "4  13524672           2726667         13524672"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups = temp_MERGECASES.groupby('IronwoodWinnerID')\n",
    "filtered_df = groups.filter(lambda x: x['IronwoodLoserID'].nunique() > 1)\n",
    "filtered_df.sort_values(by='IronwoodWinnerID',inplace=True,ignore_index=True)\n",
    "print(\"5.3: Check If merge case is valid, List of two loser iid are merged to one winner : \")\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4e8667c",
   "metadata": {},
   "outputs": [],
   "source": [
    "curwk_period = curwk_PERIOD_CUR_WK_v0.reset_index()\n",
    "curwk_period = pl.from_pandas(curwk_period)\n",
    "\n",
    "curwk_period = curwk_period.with_columns(\n",
    "    pl.col('PERIOD_KEY').dt.date(),\n",
    "    pl.col('WK_END_DATE').dt.date(),\n",
    "    pl.col('CAL_MONTH').dt.date()\n",
    ")\n",
    "\n",
    "curwk_period = curwk_period.with_columns(pl.col(\"PERIOD_KEY\").dt.strftime(\"%Y%m%d\").alias(\"PeriodKey\"))\n",
    "\n",
    "curwk_period = curwk_period.with_columns(pl.col(\"CAL_MONTH\").dt.strftime(\"%Y%m\").alias(\"CCYYMM\"))\n",
    "\n",
    "curwk_period=curwk_period.drop([\"PERIOD_KEY\",\"PERIOD_START_DAY\",\"PERIOD_DAYS\",\"WK_NUM\",\"445_MONTH\",\"445_MO_NUM\"])\n",
    "curwk_period.to_pandas().to_parquet(f's3://{bucket}/{curwk}curwk_period.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c5cd494",
   "metadata": {},
   "outputs": [],
   "source": [
    "#added this to modify dropweek logic , now covers split week also\n",
    "dw = (curwk_DATE_PARM_WK['WK_END_DATE'].min() - timedelta(days=7)).strftime(\"%Y-%m-%d\")\n",
    "dw_lookup = curwk_period.filter(pl.col('WK_END_DATE') == (datetime.strptime(dw, \"%Y-%m-%d\")))['PeriodKey']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6a98aa-084c-4b99-856e-a0ef0ead5308",
   "metadata": {},
   "source": [
    "##### Make sure your previous week's dataset is trimmed to its respective 105 week's worth of data ,\n",
    "- Size is a big concern here or cell crashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "478d9567-41ee-4f43-ae65-69540940f0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Historical data into looser vs non loser.\n",
    "\n",
    "#Reading Historical Data\n",
    "prewk_RAW_RX_FIN = pl.read_parquet(f's3://{bucket}/{prewk}RAW_RX_FIN.parquet')\n",
    "# Dropping 1 week form previous week historical data to have 104 weeks.\n",
    "prewk_RAW_RX_FIN = prewk_RAW_RX_FIN.filter(~pl.col('PeriodKey').is_in(dw_lookup))\n",
    "temp_MERGECASES_ids  = list(temp_MERGECASES['IID'].unique())\n",
    "temp_RAW_RX_FIN = pl.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbfab222-fb5b-4d85-ad14-21f63dbd546d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399\n",
      "399\n"
     ]
    }
   ],
   "source": [
    "chunksize = 2_000_000\n",
    "for i in range(0,len(prewk_RAW_RX_FIN),chunksize):\n",
    "    chunk = prewk_RAW_RX_FIN.slice(i, min(chunksize, len(prewk_RAW_RX_FIN) - i))\n",
    "    fc = chunk.filter(~pl.col('IronwoodID').is_in(temp_MERGECASES_ids))\n",
    "    temp_RAW_RX_FIN = temp_RAW_RX_FIN.vstack(fc)\n",
    "    \n",
    "temp_MERGECASES = pl.from_pandas(temp_MERGECASES)\n",
    "temp_MERGECASES = temp_MERGECASES.rename({'IID' : 'IronwoodID'})\n",
    "temp_MERGECASES2 = prewk_RAW_RX_FIN.join(temp_MERGECASES,how = 'inner',on='IronwoodID')\n",
    "\n",
    "#QC check \n",
    "print(temp_MERGECASES2.shape[0])\n",
    "print(prewk_RAW_RX_FIN.shape[0]-temp_RAW_RX_FIN.shape[0])\n",
    "\n",
    "#print(prewk_RAW_RX_FIN.estimated_size() / 1024 / 1024 / 1024)\n",
    "#6.176180515438318"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8767fdb6-25d7-4651-a292-a690352548f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FOR MEMORY Conservation - \n",
    "del prewk_RAW_RX_FIN\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "320a03d3-c07b-4db3-bbf4-c4eed2f33a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_cols = ['IronwoodWinnerID','MarketID','MarketName','MKT_CD','ChannelID','ChannelName','ProductID','ProductName','PeriodKey']\n",
    "sum_cols = ['TotalRx','TotalQuantity','TotalFactoredQuantity','NewRx','NewQuantity','NewFactoredQuantity']\n",
    "\n",
    "#perform groupby and calc function \n",
    "temp_MERGECASES3 = temp_MERGECASES2.group_by(group_cols).agg([pl.col(c).sum() for c in sum_cols])\n",
    "temp_MERGECASES3= temp_MERGECASES3.rename({'IronwoodWinnerID':'IronwoodID'}) #this was mergecases4 step in sas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b71c955-1d39-4429-9e28-694a20626d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.3.1: Check to see if current xpn has loser id\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "temp_RAW_RX_CUR_WK = pl.from_pandas(curwk_RAW_RX_CUR_WK)\n",
    "del curwk_RAW_RX_CUR_WK\n",
    "gc.collect()\n",
    "\n",
    "#/*QC TO SEE IF CURRENT WEEK XPN HAS LODERID*/\n",
    "temp_CURRENTWEEK_CHECK = temp_RAW_RX_CUR_WK.join(temp_MERGECASES,how = 'inner',on='IronwoodID')\n",
    "\n",
    "print(\"5.3.1: Check to see if current xpn has loser id\")\n",
    "print(len(temp_CURRENTWEEK_CHECK))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a8b5dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cat Data Fix - #need to make this cat type as well to merge with data\n",
    "temp_RAW_RX_CUR_WK = temp_RAW_RX_CUR_WK.with_columns([\n",
    "    pl.col('MarketID').cast(pl.Utf8).cast(pl.Categorical),\n",
    "    pl.col('MarketName').cast(pl.Utf8).cast(pl.Categorical),\n",
    "    pl.col('MKT_CD').cast(pl.Utf8).cast(pl.Categorical),\n",
    "    pl.col('ChannelID').cast(pl.Utf8).cast(pl.Categorical),\n",
    "    pl.col('ChannelName').cast(pl.Utf8).cast(pl.Categorical),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32210869-312e-4991-963a-c7066629f7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22355393, 15)\n"
     ]
    }
   ],
   "source": [
    "# Combining Historical Data without Loosers + Hist Data with loosers + Rx Delta from raw\n",
    "temp_RAW_RX_FIN1 = pl.DataFrame()\n",
    "#temp_RAW_RX_FIN temp_MERGECASES3 temp_RAW_RX_CUR_WK\n",
    "\n",
    "#need to rearrange column sequence to use vstack-\n",
    "temp_MERGECASES3 = temp_MERGECASES3.select(temp_RAW_RX_FIN.columns)\n",
    "temp_RAW_RX_CUR_WK = temp_RAW_RX_CUR_WK.select(temp_RAW_RX_FIN.columns)\n",
    "\n",
    "temp_RAW_RX_FIN1 = temp_RAW_RX_FIN.vstack(temp_MERGECASES3).vstack(temp_RAW_RX_CUR_WK)\n",
    "\n",
    "print(temp_RAW_RX_FIN1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a047cc01-7cfc-4994-8c1d-c9e21e1a0692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del temp_RAW_RX_FIN\n",
    "del temp_MERGECASES3\n",
    "del temp_RAW_RX_CUR_WK\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5492f892-9959-4fb9-ab00-362d5d9ad2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cat Data Fix - #add more and fix later - ONE time action , now historical data is already of type cat | only apply fix on Delta\n",
    "# temp_RAW_RX_FIN1 = temp_RAW_RX_FIN1.with_columns([\n",
    "#     pl.col('MarketID').cast(pl.Utf8).cast(pl.Categorical),\n",
    "#     pl.col('MarketName').cast(pl.Utf8).cast(pl.Categorical),\n",
    "#     pl.col('MKT_CD').cast(pl.Utf8).cast(pl.Categorical),\n",
    "#     pl.col('ChannelID').cast(pl.Utf8).cast(pl.Categorical),\n",
    "#     pl.col('ChannelName').cast(pl.Utf8).cast(pl.Categorical),\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df495473-0f41-4867-8b45-fa5cf06db324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2092536566779017"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this should be around 3.2 GB , if more kernel might crash | tested at 13 GB available Ram Env\n",
    "temp_RAW_RX_FIN1.estimated_size(unit='gb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33a8283a-3809-4b18-9f69-cd8da3271509",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This approach Crashed the kernel \n",
    "\n",
    "group_cols = ['MarketID','MarketName','MKT_CD','ChannelID','ChannelName','IronwoodID','ProductID','ProductName','PeriodKey']\n",
    "sum_cols = ['TotalRx','TotalQuantity','TotalFactoredQuantity','NewRx','NewQuantity','NewFactoredQuantity']\n",
    "\n",
    "#perform groupby and calc function \n",
    "curwk_RAW_RX_FIN = pl.DataFrame()\n",
    "curwk_RAW_RX_FIN = temp_RAW_RX_FIN1.group_by(group_cols).agg([pl.col(c).sum() for c in sum_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67af45fa-8a92-4a4f-b2ef-85292bacc123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This took 30 Sec to export at 19 Million records , File size of 230 MB \n",
    "# FURTHER TESTING FOR write_parquet() arguments like compression type & level is requried\n",
    "\n",
    "#curwk_RAW_RX_FIN.write_parquet(curwk+'\\\\RAW_RX_FIN.parquet',compression='zstd',compression_level=10,use_pyarrow=True)\n",
    "\n",
    "curwk_RAW_RX_FIN.to_pandas().to_parquet(\n",
    "    f's3://{bucket}/{curwk}RAW_RX_FIN.parquet',compression='snappy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3bb63823-09b4-422d-ad86-e9961f0bf8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This should always be 105 ! \n",
      "105\n",
      "This should always be 0 ! \n",
      "0\n"
     ]
    }
   ],
   "source": [
    "temp_RX_PERIOD_CUR_WK = pl.DataFrame()\n",
    "temp_RX_PERIOD_CUR_WK = curwk_RAW_RX_FIN.join(curwk_period,how = 'left',on = 'PeriodKey')\n",
    "check = list(temp_RX_PERIOD_CUR_WK['WK_END_DATE'].unique())\n",
    "print(\"This should always be 105 ! \")\n",
    "print(len(check))\n",
    "check = temp_RX_PERIOD_CUR_WK.filter(pl.col(\"WK_END_DATE\").is_null())\n",
    "print(\"This should always be 0 ! \")\n",
    "print(len(check))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17cb8e3-99ea-4cf7-8165-ad081c58385d",
   "metadata": {},
   "source": [
    "### SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "361eda21-647f-42c5-b74c-f65b86ce6238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_cols = ['IronwoodID','WK_END_DATE','CCYYMM','MKT_CD','MarketName','ChannelID','ChannelName','ProductID','ProductName']\n",
    "sum_cols = ['TotalRx','TotalQuantity','TotalFactoredQuantity','NewRx','NewQuantity','NewFactoredQuantity']\n",
    "\n",
    "# #perform groupby and calc function \n",
    "curwk_RX_PERIOD_WKSUM_CUR_WK = pl.DataFrame()\n",
    "curwk_RX_PERIOD_WKSUM_CUR_WK = temp_RX_PERIOD_CUR_WK.group_by(group_cols).agg([pl.col(c).sum() for c in sum_cols])\n",
    "\n",
    "del temp_RX_PERIOD_CUR_WK\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f1eea9a-2339-4dc4-8e0e-fdfeff076cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.4: Check If There Is Any New Product Not Captured In Standard Market Definition\n",
      "{'HEPTALAC', 'CONSTILAC', 'EVALOSE', 'PEG 3350-GRX', 'CATULAC', 'CHRONULAC', 'FREELAX', 'CALULOSE', 'CHOLAC', 'CEPHULAC', 'DUPHALAC'}\n"
     ]
    }
   ],
   "source": [
    "#/*Check If There Is Any New Product Not Captured In Standard Market Definition*/\n",
    "std_sec_def = pl.read_parquet(f's3://{bucket}/PYADM/reference/std_sec_def.parquet')\n",
    "mkt_bin = set(std_sec_def['PRODUCT_NAME'].unique())\n",
    "prod_list = set(curwk_RX_PERIOD_WKSUM_CUR_WK['ProductName'].unique())\n",
    "print(\"5.4: Check If There Is Any New Product Not Captured In Standard Market Definition\")\n",
    "print(mkt_bin-prod_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e52f6e50-d90c-4e75-a717-89d7c62235e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting to use for other calc-\n",
    "curwk_RX_PERIOD_WKSUM_CUR_WK.to_pandas().to_parquet(\n",
    "    f's3://{bucket}/{curwk}RX_PERIOD_WKSUM_CUR_WK.parquet',compression='snappy'\n",
    ")\n",
    "# END OF 5th CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce4df8ab-7762-4784-8576-000403ad47f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## QC TESTING FOR 2023-12-08's Run : Data seems to be correct and ending up with 105 weeks worth of data\n",
    "# but for some reason when i try to sum it up , kernel is crashing now # Needs more looking into\n",
    "\n",
    "# Notes for future :\n",
    "# Really need to come up with a way to perform aggrgation and summing for curwk.RAW_RX_FIN in chunks , \n",
    "# try exploring sorting algorithms , and then process chunks \n",
    "# current approach is a very unreliable method to execute this and WILL NOT SCALE IN THE FUTURE IF number of HCPS start going up\n",
    "# Even Truncating data to 105 will not suffice indefinately"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
