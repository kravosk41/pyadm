{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "775afce1-de39-4cc6-8101-aaf43978fd2b",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4456c9c-0eaf-44d5-bc60-8c24d3332bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import polars as pl\n",
    "import gc\n",
    "import numpy as np\n",
    "import s3fs\n",
    "import boto3\n",
    "from io import BytesIO as bo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db2b610-bf92-44c9-88aa-2c82e921976d",
   "metadata": {},
   "source": [
    "Date Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ea8066f-578e-4cd0-8c73-b64995ac7e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables -\n",
    "this_day = datetime.today()\n",
    "### FOR TESTING - REMOVE LATER ### \n",
    "this_day = this_day - timedelta(days=7)\n",
    "####\n",
    "days_to_monday = (this_day.weekday() - 0) % 7\n",
    "monday = this_day - timedelta(days=days_to_monday)\n",
    "\n",
    "CUR_PROC_WK = monday.strftime(\"%Y%m%d\")\n",
    "\n",
    "PRE_PROC_WK0 = monday - timedelta(days=7)\n",
    "PRE_PROC_WK = str(PRE_PROC_WK0.year) + str(PRE_PROC_WK0.month).zfill(2) + str(PRE_PROC_WK0.day).zfill(2)\n",
    "\n",
    "CUR_WK0 = monday - timedelta(days=17)\n",
    "CUR_WK = str(CUR_WK0.year) + str(CUR_WK0.month).zfill(2) + str(CUR_WK0.day).zfill(2)\n",
    "\n",
    "PRE_WK0 = monday - timedelta(days=24)\n",
    "PRE_WK = PRE_WK0.strftime(\"%Y%m%d\")\n",
    "\n",
    "MONTH_OFF = CUR_WK0.replace(day=1).date()\n",
    "QTR = f'{CUR_WK0.year}Q{(CUR_WK0.month-1)//3+1}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5aafeee3-9f61-49e7-ad20-901c754643ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_day_qtr = pd.Timestamp(CUR_WK0.year, 3 * ((CUR_WK0.month - 1) // 3) + 1, 1)\n",
    "#if first day of qtr is friday -\n",
    "if first_day_qtr.weekday() == 4:\n",
    "    FIRWK_0 = first_day_qtr\n",
    "else:\n",
    "    FIRWK_0 = first_day_qtr + pd.DateOffset(days=(4 - first_day_qtr.weekday() + 7)%7)\n",
    "FIRWK_0 = FIRWK_0.to_pydatetime()\n",
    "FIRWK_0 = datetime(FIRWK_0.year, FIRWK_0.month, FIRWK_0.day)\n",
    "\n",
    "LASWK = first_day_qtr - pd.DateOffset(days=1)\n",
    "LASWK = LASWK.to_pydatetime()\n",
    "#SATURDAY of the LAST xponent data week \n",
    "CUT_OFF_Fir_0 = FIRWK_0 -timedelta(days=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9be233d8-daa2-49b6-9719-07f676537bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'vortex-staging-a65ced90'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87483d58-2160-4dc4-9f2b-9f94d3dee970",
   "metadata": {},
   "source": [
    "Library names and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa606724-ab89-45b0-a8d6-0b85ed06c95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIBNAMES\n",
    "raw_path = f'PYADM/raw/{CUR_PROC_WK}/inbound/'\n",
    "curwk = f'PYADM/raw/{CUR_PROC_WK}/dataframes/'\n",
    "prewk = f'PYADM/raw/{PRE_PROC_WK}/dataframes/'\n",
    "wkxpn = 'PYADM/weekly/staging/xponent/'\n",
    "mthxpn = 'PYADM/monthly/staging/xponent/'\n",
    "pwkxpn = f'PYADM/weekly/archive/{PRE_WK}/xponent/'\n",
    "out = f'PYADM/First Week TRx/{QTR}/{CUR_WK}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfcbac14-43a7-4ac5-b9bb-ad745f0affb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_RX = pl.read_parquet(f's3://{bucket}/{curwk}RAW_RX_FIN.parquet')\n",
    "RAW_RX = RAW_RX.with_columns(pl.col(\"PeriodKey\").str.to_datetime('%Y %m %d').alias('PKDate'))\n",
    "\n",
    "RAW_RX = RAW_RX.select(['IronwoodID', 'ChannelID', 'MKT_CD', 'ProductID', 'PeriodKey', 'TotalFactoredQuantity','PKDate'])\n",
    "RAW_RX = RAW_RX.rename({'TotalFactoredQuantity':'TUF'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "379c6810-0f49-4b57-addd-629c9bdfa004",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_RX = RAW_RX.with_columns(\n",
    "    pl.when(pl.col(\"PKDate\").is_between(CUT_OFF_Fir_0, LASWK))\n",
    "    .then(pl.lit('LAST'))\n",
    "    .alias(\"GROUP\")\n",
    ")\n",
    "\n",
    "RAW_RX = RAW_RX.with_columns(\n",
    "    pl.when(pl.col(\"PKDate\").is_between(LASWK + timedelta(days=1), FIRWK_0)) \n",
    "    .then(pl.lit('FIRST'))\n",
    "    .otherwise(pl.col(\"GROUP\"))\n",
    "    .alias(\"GROUP\")\n",
    ")\n",
    "\n",
    "RAW_RX = RAW_RX.filter(\n",
    "    (pl.col(\"PKDate\") >= CUT_OFF_Fir_0) & (pl.col(\"PKDate\") <= FIRWK_0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f98d118-22d1-4ad8-a80d-a441ac9cee12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.1: Check if CHANNEL_ID have missing values\n",
      "shape: (2, 2)\n",
      "┌───────────┬────────┐\n",
      "│ ChannelID ┆ count  │\n",
      "│ ---       ┆ ---    │\n",
      "│ cat       ┆ u32    │\n",
      "╞═══════════╪════════╡\n",
      "│ 2         ┆ 7812   │\n",
      "│ 1         ┆ 223251 │\n",
      "└───────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "print(\"10.1: Check if CHANNEL_ID have missing values\")\n",
    "freq = RAW_RX['ChannelID'].value_counts()\n",
    "print(freq)\n",
    "# missing = RAW_RX['ChannelID'].is_null().sum()\n",
    "# print(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "672d97e1-b7bf-464b-a675-fa1b94be8465",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_RX_LAX = RAW_RX.filter(pl.col('MKT_CD')=='LAX') #Step might be reudnant , we only have LAX data anyways.\n",
    "std_sec_def = pl.read_parquet(f's3://{bucket}/PYADM/reference/std_sec_def.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec96e270-5c6e-4b4e-a493-44042a4007ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_with_zeros(val):\n",
    "    return str(val).zfill(8)\n",
    "\n",
    "RAW_RX_LAX1 = RAW_RX_LAX.with_columns(pl.col('ProductID').map_elements(pad_with_zeros,return_dtype=pl.String))\n",
    "\n",
    "rename_items = {'IronwoodID':'IID','ProductID':'PG_ID'}\n",
    "RAW_RX_LAX1 = RAW_RX_LAX1.rename(rename_items)\n",
    "\n",
    "RAW_RX_LAX1 = RAW_RX_LAX1.join(std_sec_def,on='PG_ID',how='left')\n",
    "RAW_RX_LAX2 = RAW_RX_LAX1.filter((pl.col('PROD_CD')!='LIN')|(pl.col('PROD_CD').is_null()))\n",
    "RAW_RX_LAX2 = RAW_RX_LAX2.filter((pl.col('ChannelID')==\"1\") | (pl.col('ChannelID')==\"2\"))  #This step is redundant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "066f4ab7-3809-496a-901d-a4de3a85c90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAX_N = pl.DataFrame()\n",
    "LAX_N = RAW_RX_LAX2.group_by(['IID','GROUP','PROD_CD']).agg(pl.col('TUF').sum())\n",
    "\n",
    "LIN_DN_LAS = LAX_N.filter(\n",
    "    (pl.col('PROD_CD').is_in(['LI1','LI2','LI3'])) & (pl.col('GROUP')=='LAST')\n",
    ")\n",
    "\n",
    "LIN_DN_LAS = LIN_DN_LAS.group_by('IID').agg(pl.col('TUF').sum())\n",
    "LIN_DN_LAS = LIN_DN_LAS.rename({'TUF':'LINFTUF13'})\n",
    "\n",
    "LIN_DN_FIR = LAX_N.filter(\n",
    "    (pl.col('PROD_CD').is_in(['LI1','LI2','LI3'])) & (pl.col('GROUP')=='FIRST') #Is callled 'FIRS' in sas code for some reason\n",
    ")\n",
    "\n",
    "LIN_DN_FIR = LIN_DN_FIR.group_by('IID').agg(pl.col('TUF').sum())\n",
    "LIN_DN_FIR = LIN_DN_FIR.rename({'TUF':'LINFTUF0'})\n",
    "\n",
    "LAX_DN_LAS = LAX_N.filter(\n",
    "    ((pl.col('PROD_CD').is_null() | ~(pl.col('PROD_CD').is_in(['MOB','MOG'])))  & (pl.col('GROUP')=='LAST'))\n",
    ")\n",
    "\n",
    "LAX_DN_LAS = LAX_DN_LAS.group_by('IID').agg(pl.col('TUF').sum())\n",
    "LAX_DN_LAS = LAX_DN_LAS.rename({'TUF':'LAXMTUF13'})\n",
    "\n",
    "LAX_DN_FIR = LAX_N.filter(\n",
    "    ((pl.col('PROD_CD').is_null() | ~(pl.col('PROD_CD').is_in(['MOB','MOG'])))  & (pl.col('GROUP')=='FIRST')) \n",
    ")\n",
    "\n",
    "# dev comment -\n",
    "# while filtering for negation of MOB , MOG | any feilds with null are considered False by the boolean expression | Hence ,\n",
    "# we explictly force to keep null values.\n",
    "\n",
    "\n",
    "LAX_DN_FIR = LAX_DN_FIR.group_by('IID').agg(pl.col('TUF').sum())\n",
    "LAX_DN_FIR = LAX_DN_FIR.rename({'TUF':'LAXMTUF0'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83547c29-b06a-44ff-a606-d5dfbe0ab009",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAX_DN = (LIN_DN_LAS.join(LIN_DN_FIR, on='IID', how='outer_coalesce')\n",
    "                       .join(LAX_DN_LAS, on='IID', how='outer_coalesce')\n",
    "                       .join(LAX_DN_FIR, on='IID', how='outer_coalesce'))\n",
    "\n",
    "# Then, filter the rows where all values are null across the row\n",
    "LAX_DN = LAX_DN.filter(pl.any_horizontal(pl.col('*').is_not_null())) #Should I remove this step ?\n",
    "\n",
    "LAX_DN = LAX_DN.with_columns([pl.col('*').fill_null(0)])\n",
    "#LAX_DN.write_parquet(out+'\\\\LAX_DN.parquet',compression='zstd',compression_level=10,use_pyarrow=True)\n",
    "LAX_DN.to_pandas().to_parquet(f's3://{bucket}/{out}LAX_DN.parquet',compression='snappy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b6f017e-1798-44bd-8086-0edecf6b5c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate : When Filtering out all prod_Cd = LIN , records with GROUP = LAST also get filtered out\n",
    "# only have POLYETHYLENE GLY(OTC)\t as LAST wek in raw data ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388caed6-65e4-409d-9657-293e13f13a34",
   "metadata": {},
   "source": [
    "### Vouchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0cb84f31-665b-47fd-aa4e-6f1a20b69f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VOUCHER = pl.read_parquet(curwk+\"\\\\VOUCHER.parquet\")\n",
    "VOUCHER = pl.read_parquet(f's3://{bucket}/{curwk}VOUCHER.parquet')\n",
    "VOUCHER = VOUCHER.rename({'FACTORED_TRX':'TUF'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b83e86e2-9067-4252-af84-b056a2a1ca73",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOUCHER = VOUCHER.with_columns(\n",
    "    pl.when(pl.col(\"WEEK_ENDING_DATE\").is_between(CUT_OFF_Fir_0, LASWK))\n",
    "    .then(pl.lit('LAST'))\n",
    "    .alias(\"GROUP\")\n",
    ")\n",
    "\n",
    "VOUCHER = VOUCHER.with_columns(\n",
    "    pl.when(pl.col(\"WEEK_ENDING_DATE\").is_between(LASWK + timedelta(days=1), FIRWK_0)) \n",
    "    .then(pl.lit('FIRST'))\n",
    "    .otherwise(pl.col(\"GROUP\"))\n",
    "    .alias(\"GROUP\")\n",
    ")\n",
    "\n",
    "VOUCHER = VOUCHER.filter(\n",
    "    (pl.col(\"WEEK_ENDING_DATE\") >= CUT_OFF_Fir_0) & (pl.col(\"WEEK_ENDING_DATE\") <= FIRWK_0)\n",
    ")\n",
    "\n",
    "VOUCHER_LIN = VOUCHER.filter(pl.col('GROUP_ID').is_in(['47711 - 00000035', '47711 - 00000034', '47711 - 00000033'])) # This step might be redundant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e9b8ee-1b19-4d01-883f-a9bb418eb321",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOUCHER_LIN_LAS = VOUCHER_LIN.filter(pl.col('GROUP')=='LAST')\n",
    "VOUCHER_LIN_LAS = VOUCHER_LIN_LAS.group_by('IID').agg(pl.col('TUF').sum())\n",
    "VOUCHER_LIN_LAS = VOUCHER_LIN_LAS.rename({'TUF':'LINVTUF13'})\n",
    "\n",
    "VOUCHER_LIN_FIR = VOUCHER_LIN.filter(pl.col('GROUP')=='FIRST')\n",
    "VOUCHER_LIN_FIR = VOUCHER_LIN_FIR.group_by('IID').agg(pl.col('TUF').sum())\n",
    "VOUCHER_LIN_FIR = VOUCHER_LIN_FIR.rename({'TUF':'LINVTUF0'})\n",
    "\n",
    "LIN_VOUCHER = VOUCHER_LIN_LAS.join(VOUCHER_LIN_FIR, on='IID', how='outer_coalesce')\n",
    "LIN_VOUCHER = LIN_VOUCHER.with_columns([pl.col('*').fill_null(0)])\n",
    "\n",
    "#LIN_VOUCHER.write_parquet(out+'\\\\VOUCHER.parquet',compression='zstd',compression_level=10,use_pyarrow=True)\n",
    "LIN_VOUCHER.to_pandas().to_parquet(f's3://{bucket}/{out}VOUCHER.parquet',compression='snappy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
