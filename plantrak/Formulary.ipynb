{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05635cd7-ff7b-4370-8930-b29f9fbc3f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import polars as pl\n",
    "import gc\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import s3fs\n",
    "import boto3\n",
    "from io import BytesIO as bo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c058c4a2-7212-45e0-9e42-03d237fe2dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables -\n",
    "this_day = datetime.today()\n",
    "### FOR TESTING - REMOVE LATER ### \n",
    "this_day = this_day - timedelta(days=7)\n",
    "####\n",
    "days_to_monday = (this_day.weekday() - 0) % 7\n",
    "monday = this_day - timedelta(days=days_to_monday)\n",
    "\n",
    "CUR_PROC_WK = monday.strftime(\"%Y%m%d\")\n",
    "\n",
    "PRE_PROC_WK0 = monday - timedelta(days=7)\n",
    "PRE_PROC_WK = str(PRE_PROC_WK0.year) + str(PRE_PROC_WK0.month).zfill(2) + str(PRE_PROC_WK0.day).zfill(2)\n",
    "\n",
    "CUR_WK0 = monday - timedelta(days=17)\n",
    "CUR_WK = str(CUR_WK0.year) + str(CUR_WK0.month).zfill(2) + str(CUR_WK0.day).zfill(2)\n",
    "\n",
    "PRE_WK0 = monday - timedelta(days=24)\n",
    "PRE_WK = PRE_WK0.strftime(\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bd66350-4846-41c5-ba47-0eee891f6864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing IW Release File \n",
    "s3 = s3fs.S3FileSystem()\n",
    "bucket_list = s3.listdir(f'vortex-staging-a65ced90/PYADM/raw/{CUR_PROC_WK}/inbound/')\n",
    "for file in bucket_list:\n",
    "    if (file['Key'].__contains__(f\"IRWD_RELEASE_WKLY_{CUR_PROC_WK}\")):\n",
    "        release_file = file['Key']\n",
    "\n",
    "# Reading Release File -\n",
    "s3_client = boto3.client('s3')\n",
    "bucket = release_file.split('/')[0]\n",
    "file_key = release_file.split('/',1)[1]\n",
    "\n",
    "adm = pd.read_csv(f's3://{bucket}/{file_key}',sep='|')\n",
    "adm1 = adm[CUR_PROC_WK].tolist()\n",
    "\n",
    "for item in adm1:\n",
    "    if item.startswith('P_OUT_110_FORMULARY_GROUP_REDUCED_'):\n",
    "        FRM_TIMESTAMP_1 = item.split('_')[-1].split('.')[0]\n",
    "    elif item.startswith('P_OUT_110_FORMULARY_GROUP_'):\n",
    "        FRM_TIMESTAMP_2 = item.split('_')[-1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ffe66db-13ea-4384-a8dc-f3588e1d4836",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIBNAMES\n",
    "raw_path = f'PYADM/raw/{CUR_PROC_WK}/inbound/'\n",
    "curwk = f'PYADM/raw/{CUR_PROC_WK}/dataframes/'\n",
    "prewk = f'PYADM/raw/{PRE_PROC_WK}/dataframes/'\n",
    "ptk = f'PYADM/weekly/archive/{CUR_WK}/plantrak/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f52206-051b-4e24-b1b2-b54652fcc3f5",
   "metadata": {},
   "source": [
    "### Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd797632-ae3b-4c7e-9efa-421d3b50da71",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = f's3://{bucket}/{raw_path}P_OUT_110_FORMULARY_GROUP_REDUCED_{FRM_TIMESTAMP_1}.TXT'\n",
    "\n",
    "FORMULARY = pd.read_csv(\n",
    "    input_file,delimiter='|',\n",
    "    dtype = {0:str}\n",
    ")\n",
    "FORMULARY = pl.from_pandas(FORMULARY)\n",
    "FORMULARY = FORMULARY.unique(keep = 'first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94615f74-e1cf-4b9a-9601-a19298a115fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_type_2_mapping_dict = {\n",
    "    \"Cash\": \"Cash\",\n",
    "    \"Com\": \"Commercial\",\n",
    "    \"FFS\": \"Medicaid\",\n",
    "    \"HIX\": \"Commercial\",\n",
    "    \"Mgd Medicaid\": \"Medicaid\",\n",
    "    \"Part D\": \"Medicare Part D\",\n",
    "    \"Voucher\": \"Other\"\n",
    "} # add clause for \"\" data or none data as well if needed\n",
    "\n",
    "#mapping_dict = {**mapping_dict, **df[\"GROUP_TYPE\"].unique().to_dict()} before the mapping operation. \n",
    "#This will add all unique values in GROUP_TYPE to the dictionary with the same value.\n",
    "\n",
    "FORMULARY0 = FORMULARY.with_columns(\n",
    "    pl.col(\"GROUP_TYPE\").replace(group_type_2_mapping_dict).alias(\"GROUP_TYPE2\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1c63747-e0e6-41b4-9ec0-b85345410d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_to_pfam_cd_mapping_dict = {\n",
    "    \"AMZ\": \"LUB\",\n",
    "    \"APNL\": \"ALP\",\n",
    "    \"CAN\": \"CAN\",\n",
    "    \"DEL\": \"DEL\",\n",
    "    \"DUZ\": \"DUZ\",\n",
    "    \"LIN\": \"LIN\",\n",
    "    \"TRU\": \"TRU\",\n",
    "    \"ULC\": \"ULT\",\n",
    "    \"VZ\": \"VIB\",\n",
    "    \"XFN\": \"XIF\",\n",
    "    \"ZUR\": \"ZUR\",\n",
    "    \"LUB\": \"LUB\",\n",
    "    \"MOT\": \"MOT\",\n",
    "    \"IBR\": \"IRL\",  # Ibsrela\n",
    "    \"ZEL\": \"ZEL\",  # Zelnorm\n",
    "    \"CON\": \"LAC\",  # Constulose\n",
    "    \"ENU\": \"LAC\",  # Enulose\n",
    "    \"GEC\": \"LAC\",  # Genralac\n",
    "    \"KRI\": \"LAC\",  # Kristalose\n",
    "    \"LAC\": \"LAC\",  # Lactulose\n",
    "    None: \"XXX\",\n",
    "    \"\": \"XXX\"  # For blank rows\n",
    "}\n",
    "FORMULARY1 = FORMULARY0.with_columns(\n",
    "    pl.col(\"BRAND\").replace(brand_to_pfam_cd_mapping_dict).alias(\"PFAM_CD\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39e8b982-a3ec-42e3-a675-c131969572b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_sec_def = pl.read_parquet(f's3://{bucket}/PYADM/reference/std_sec_def.parquet',columns = ['PFAM_CD', 'PFAM_NAME', 'MKT_CD', 'MKT_NAME'])\n",
    "\n",
    "#since you are only keeping 4 columns you need to drop dups\n",
    "std_sec_def = std_sec_def.unique(subset=['PFAM_CD', 'PFAM_NAME', 'MKT_CD', 'MKT_NAME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3395a409-0669-4d51-8c36-3b3fb5b6854d",
   "metadata": {},
   "outputs": [],
   "source": [
    "FORMULARY2 = FORMULARY1.join(std_sec_def,on='PFAM_CD',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "113169e4-67e2-4486-88ec-82bcf0696b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment for QC\n",
    "# frequency_table = FORMULARY2.to_pandas().groupby(['FORMULARY_GROUP_STATUS']).size().reset_index(name='FREQUENCY')\n",
    "# frequency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c59bc92a-400a-4525-b7ef-9f4f65b2c25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequency_table = FORMULARY2.to_pandas().groupby(['BRAND']).size().reset_index(name='FREQUENCY')\n",
    "# frequency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20caa6be-f60c-4257-830b-6fdef9b80a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FORMULARY2.write_parquet(ptk+'\\\\FORMULARY.parquet',compression='zstd',compression_level=10,use_pyarrow=True)\n",
    "FORMULARY2.to_pandas().to_parquet(f's3://{bucket}/{ptk}FORMULARY.parquet', compression='snappy')\n",
    "# #Export Done!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff811bef-d9db-42e1-bb90-1321e4a0d760",
   "metadata": {},
   "source": [
    "## Full Formulary For Steve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f98687a9-7f86-4f6f-a87e-61da43c63d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_file = raw_path + 'P_OUT_110_FORMULARY_GROUP_' + str(FRM_TIMESTAMP_2) + \".TXT\"\n",
    "input_file = f's3://{bucket}/{raw_path}P_OUT_110_FORMULARY_GROUP_{FRM_TIMESTAMP_2}.TXT'\n",
    "FORMULARY = pd.read_csv(\n",
    "    input_file,delimiter='|',\n",
    "    dtype = {0:str,1:str,4:str,8:str},\n",
    "    parse_dates=[10]\n",
    ")\n",
    "FORMULARY['DATA_EFFECITVE_DATE'] = FORMULARY['DATA_EFFECITVE_DATE'].dt.date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e49f0882-d423-4401-853d-b1053d8ac1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records Dropped :  0\n"
     ]
    }
   ],
   "source": [
    "dedup1 = ['IMS_PLAN_ID', 'IRWD_FGN_NAME', 'BRAND', 'GROUP_TYPE', 'FORMULARY_GROUP_STATUS','PARENT_NM','STATUS']\n",
    "\n",
    "b = FORMULARY.shape[0]\n",
    "FORMULARY.drop_duplicates(subset=dedup1, keep='first', inplace=True, ignore_index=False)\n",
    "a = FORMULARY.shape[0]\n",
    "print(\"Records Dropped : \",b-a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1bb0c6c2-1552-41d7-97fa-6a16762f6e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_list1= ['IMS_PLAN_ID', 'IRWD_FGN_NAME', 'BRAND', 'GROUP_TYPE', 'FORMULARY_GROUP_STATUS', 'STATUS','LIVES']\n",
    "sort_type1= [True]*6 + [False]\n",
    "FORMULARY.sort_values(by=sort_list1,ascending=sort_type1,inplace=True,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a63e90c3-df9a-4d61-ae34-580f259a9544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records Dropped :  0\n"
     ]
    }
   ],
   "source": [
    "dedup2 = ['IMS_PLAN_ID', 'IRWD_FGN_NAME' ,'BRAND', 'GROUP_TYPE' ,'FORMULARY_GROUP_STATUS', 'STATUS']\n",
    "b = FORMULARY.shape[0]\n",
    "FORMULARY.drop_duplicates(subset=dedup2, keep='first', inplace=True, ignore_index=False)\n",
    "a = FORMULARY.shape[0]\n",
    "print(\"Records Dropped : \",b-a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc6bc6a6-fe89-4397-9222-934b08975c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "FORMULARY = pl.from_pandas(FORMULARY)\n",
    "FORMULARY0 = FORMULARY.with_columns(\n",
    "    pl.col(\"GROUP_TYPE\").replace(group_type_2_mapping_dict).alias(\"GROUP_TYPE2\")\n",
    ")\n",
    "FORMULARY1 = FORMULARY0.with_columns(\n",
    "    pl.col(\"BRAND\").replace(brand_to_pfam_cd_mapping_dict).alias(\"PFAM_CD\")\n",
    ")\n",
    "\n",
    "FORMULARY2 = FORMULARY1.join(std_sec_def,on='PFAM_CD',how='inner')\n",
    "FORMULARY2 = FORMULARY2.sort(by='PFAM_CD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11e4fde1-bc94-444c-a06b-90360ce79314",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FORMULARY2.write_parquet(ptk+'\\\\FORMULARY_orig.parquet',compression='zstd',compression_level=10,use_pyarrow=True)\n",
    "FORMULARY2.to_pandas().to_parquet(f's3://{bucket}/{ptk}FORMULARY_orig.parquet',compression='snappy')\n",
    "#Export Done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
