{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3cd44fe-7b0a-4c27-a0a6-49553c379350",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "403c5f99-3174-44bc-9a5f-41f8a39b6a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_day = datetime.today()\n",
    "# FOR TESTING\n",
    "this_day = this_day - timedelta(days=21)\n",
    "###\n",
    "days_to_monday = (this_day.weekday() - 0) % 7\n",
    "monday = this_day - timedelta(days=days_to_monday)\n",
    "CUR_PROC_WK = monday.strftime(\"%Y%m%d\")\n",
    "\n",
    "CUR_MTH = monday - timedelta(days=17)\n",
    "CUR_MTH = CUR_MTH.replace(day=1)\n",
    "CUR_MTH = CUR_MTH.strftime(\"%Y%m\")\n",
    "\n",
    "bucket = 'vortex-staging-a65ced90'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7177807-df0f-442c-a529-710b9139d88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYADM/monthly/archive/202405/plantrak/\n"
     ]
    }
   ],
   "source": [
    "#libs\n",
    "curwk = f'PYADM/raw/{CUR_PROC_WK}/dataframes/'\n",
    "ptk = f'PYADM/monthly/archive/{CUR_MTH}/plantrak/'\n",
    "\n",
    "\n",
    "print(ptk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9d33342-b89c-4707-b0a8-397d6c70cbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NMLLAX= pl.read_parquet(ptk+'\\\\LAX_N.parquet') \n",
    "\n",
    "NMLLAX= pl.read_parquet(f's3://{bucket}/{ptk}LAX_N.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e9b1f51-dc99-47df-a53e-b5b15c1dc293",
   "metadata": {},
   "outputs": [],
   "source": [
    "NMLLAX = NMLLAX.filter(pl.col('PROD_CD') != \"\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63217c60-984b-4f09-b1ee-2b9f7eaceff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "RX_PERIOD_MTHSORT = NMLLAX[['MonthKey']].unique()\n",
    "RX_PERIOD_MTHSORT = RX_PERIOD_MTHSORT.with_columns(\n",
    "    pl.col('MonthKey').cast(pl.Utf8)\n",
    "    .str.to_datetime(format='%Y%m%d')\n",
    "    .alias('PK')\n",
    ")\n",
    "RX_PERIOD_MTHSORT = RX_PERIOD_MTHSORT.sort(by=['PK'])\n",
    "RX_PERIOD_MTHSORT = RX_PERIOD_MTHSORT.with_row_index(name=\"I\",offset = 1)\n",
    "RX_PERIOD_MTHSORT = RX_PERIOD_MTHSORT.drop('PK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abc37197-16bd-4b72-bc24-76fed1d7127e",
   "metadata": {},
   "outputs": [],
   "source": [
    "NMLLAX = NMLLAX.join(RX_PERIOD_MTHSORT,on='MonthKey',how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "937afa97-403f-4e46-b446-9758aea56d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['TRX','NRX','TUN','NUN','TUF','NUF']\n",
    "NMLLAX = NMLLAX.with_columns([(pl.col(\"PROD_CD\").cast(pl.Utf8) + \"P_\" + pl.col(\"I\").cast(pl.Utf8)).alias(\"PROD_MT\")])\n",
    "NMLLAX = NMLLAX.select(pl.col(['IID', 'PlanID', 'PlanName', 'PayerID', 'PayerName', 'PBMID' ,'PBMName', 'TRX', 'NRX','TUN', 'NUN', 'TUF','NUF','PROD_MT']))\n",
    "NMLLAX = NMLLAX.sort('IID')\n",
    "NMLLAX = NMLLAX.with_columns(pl.col(\"PROD_MT\").cast(pl.Utf8).cast(pl.Categorical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7a30373-89f7-41ae-8ad3-92ee59c4cf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_vals = list(NMLLAX['PROD_MT'].unique()) \n",
    "full_unique_vals = []\n",
    "def unique_vals_prod_wk(col_name):   \n",
    "    parts = col_name.split('_')\n",
    "    for m in metrics:\n",
    "        full = parts[0]+m+parts[-1]\n",
    "        full_unique_vals.append(full)\n",
    "    \n",
    "for i in unique_vals:\n",
    "    unique_vals_prod_wk(i)\n",
    "\n",
    "\n",
    "full_unique_vals.sort()\n",
    "full_unique_vals =['IID','PlanID', 'PlanName', 'PayerID', 'PayerName', 'PBMID' ,'PBMName'] + full_unique_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56c9dc8-56e2-462f-af04-0831a219cf09",
   "metadata": {},
   "source": [
    "Note : Need to refactor variable names , ive reused the week QC code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e2656dd-2c65-40eb-862e-0b6ae327db9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of products in data which do not have 24 months of data :  1\n",
      "['ZEL']\n",
      "shape: (1, 2)\n",
      "┌──────┬────────────┐\n",
      "│ prod ┆ num_of_wks │\n",
      "│ ---  ┆ ---        │\n",
      "│ str  ┆ u32        │\n",
      "╞══════╪════════════╡\n",
      "│ ZEL  ┆ 17         │\n",
      "└──────┴────────────┘\n",
      "BUT !  - \n",
      "ZEL  has gaps in months\n"
     ]
    }
   ],
   "source": [
    "wk_tst = pl.DataFrame()\n",
    "wk_tst = wk_tst.with_columns(pl.Series(name='col_names_raw',values=full_unique_vals[7:]))\n",
    "\n",
    "def split_col_names(value):\n",
    "    prod = value[:3]\n",
    "    metric = value[4:7]\n",
    "    wknum = value[7:]\n",
    "    return prod, metric, wknum\n",
    "\n",
    "wk_tst = wk_tst.with_columns([pl.col(\"col_names_raw\").map_elements(split_col_names, return_dtype=pl.Object).alias(\"split_values\")])\n",
    "\n",
    "wk_tst = wk_tst.with_columns([\n",
    "    pl.col(\"split_values\").map_elements(lambda x: x[0], return_dtype=pl.Utf8).alias(\"prod\"),\n",
    "    pl.col(\"split_values\").map_elements(lambda x: x[1], return_dtype=pl.Utf8).alias(\"metric\"),\n",
    "    pl.col(\"split_values\").map_elements(lambda x: x[2], return_dtype=pl.Utf8).alias(\"wknum\"),\n",
    "])\n",
    "wk_tst = wk_tst.drop([\"split_values\",\"col_names_raw\"])\n",
    "\n",
    "res = wk_tst.group_by(['prod','metric']).agg([pl.col('wknum').n_unique().alias('num_of_wks')])\n",
    "missing_wknum = res.filter(pl.col('num_of_wks') != 24)\n",
    "missing_wknum = missing_wknum.sort(by='prod')\n",
    "print(\"Number of products in data which do not have 24 months of data : \",len(missing_wknum['prod'].unique()))\n",
    "print(list((missing_wknum['prod'].unique())))\n",
    "missmps = list((missing_wknum['prod'].unique()))\n",
    "missing_wknum_print = missing_wknum.select(pl.col(['prod','num_of_wks']))\n",
    "missing_wknum_print = missing_wknum_print.unique(subset=['prod','num_of_wks'])\n",
    "print(missing_wknum_print)\n",
    "\n",
    "wk_conti = pl.DataFrame()\n",
    "wk_conti = wk_tst.filter(pl.col('prod').is_in(missmps))\n",
    "wk_conti = wk_conti.drop('metric')\n",
    "wk_conti = wk_conti.unique(subset=['prod','wknum'])\n",
    "wk_conti = wk_conti.with_columns(pl.col(\"wknum\").cast(pl.Int32))\n",
    "\n",
    "print('BUT !  - ')\n",
    "for prod in missmps:\n",
    "    f1 = wk_conti.filter(pl.col('prod')== prod )\n",
    "    if (len(f1['wknum'].unique()) != f1['wknum'].max()):\n",
    "        print(prod,\" has gaps in months\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a9e2c9-d781-49bd-9ae6-ffa48720954f",
   "metadata": {},
   "source": [
    "# Transpose Data By HCP chunks-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b56ba8c1-6769-411a-8a48-7e5528881aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_iids = NMLLAX['IID'].unique() \n",
    "chunk_size = 10000 #Each chunk will contain 5000 HCPs worth of transactions (NOT ROWS, they may differ each chunk)\n",
    "\n",
    "iid_chunks = [unique_iids[i:i + chunk_size] for i in range(0, len(unique_iids), chunk_size)]\n",
    "#So IID_chunks is a list of lists, each list contains 5000 HCPs and number of lists is our number of chunks\n",
    "\n",
    "prod_family_market_buckets = {\n",
    "    \"MRXF\" : [\"MRGP\",\"MRBP\",\"GLYP\"],\n",
    "    \"LINF\" : [\"LI1P\",\"LI2P\",\"LI3P\"],\n",
    "    \"LUBF\" : [\"AMTP\",\"LUBP\"],\n",
    "    \"GENM\" : [\"FLXP\",\"LACP\",\"LUBP\",\"MRGP\",\"GLYP\"],\n",
    "    \"BRDM\" : [\"AMTP\",\"MRBP\",\"LI1P\",\"LI2P\",\"LI3P\",\"TRUP\",\"MOTP\",\"ZELP\",\"IRLP\"],\n",
    "    \"LAXM\" : [\"AMTP\",\"FLXP\",\"LACP\",\"LUBP\",\"MRGP\",\"MRBP\",\"LI1P\",\"LI2P\",\"LI3P\",\"TRUP\",\"GLYP\",\"MOTP\",\"ZELP\",\"IRLP\"]\n",
    "}\n",
    "\n",
    "writer = None\n",
    "df_final = pl.DataFrame()\n",
    "loop_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04e4435b-c1ec-46d8-b2b1-827fc38dcfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [03:59<00:00,  4.60s/it]\n"
     ]
    }
   ],
   "source": [
    "for iid_chunk in tqdm(iid_chunks):\n",
    "    \n",
    "    # if loop_counter == 11:\n",
    "    #     break\n",
    "    \n",
    "    df_chunk = NMLLAX.filter(pl.col('IID').is_in(iid_chunk))\n",
    "    \n",
    "    df_pivot_chunk = df_chunk.pivot(\n",
    "        values=metrics,index=['IID','PlanID','PlanName','PayerID','PayerName','PBMID','PBMName'],\n",
    "        columns='PROD_MT',\n",
    "        maintain_order=True,\n",
    "        sort_columns=True\n",
    "    )\n",
    "    \n",
    "    del df_chunk\n",
    "    gc.collect()\n",
    "    \n",
    "    df_pivot_chunk = df_pivot_chunk.select(\n",
    "        pl.all().name.map(\n",
    "            lambda col_name: col_name.split('_')[3] + col_name.split('_')[0] + col_name.split('_')[-1] if 'PROD_MT' in col_name else col_name\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    missing_cols = set(full_unique_vals) - set(df_pivot_chunk.columns)\n",
    "\n",
    "    if missing_cols:\n",
    "        df_missing = pl.DataFrame({col: pl.Series([None]*len(df_pivot_chunk), dtype=pl.Float64) for col in missing_cols})\n",
    "        df_pivot_chunk = pl.concat([df_pivot_chunk, df_missing], how='horizontal')\n",
    "    \n",
    "    del df_missing\n",
    "    gc.collect()\n",
    "\n",
    "    df_pivot_chunk = df_pivot_chunk.select(full_unique_vals)\n",
    "    \n",
    "    for prod_family, prod_codes in prod_family_market_buckets.items():\n",
    "        for metric in metrics:\n",
    "            prod_metric_combinations = {prod_code + metric for prod_code in prod_codes}\n",
    "            relevant_columns = [col for col in full_unique_vals if any(comb  in col for comb in prod_metric_combinations)]\n",
    "            relevant_columns = [(col, col.split(metric)) for col in relevant_columns]\n",
    "            month_numbers = sorted(set(int(parts[-1]) for col, parts in relevant_columns))\n",
    "            for month_number in month_numbers:\n",
    "                new_column = prod_family + metric + str(month_number)\n",
    "                month_columns = [col for col, parts in relevant_columns if parts[-1] == str(month_number)]\n",
    "                df_pivot_chunk = df_pivot_chunk.with_columns(sum(pl.col(c) for c in month_columns).alias(new_column))\n",
    "\n",
    "    df_final = df_final.vstack(df_pivot_chunk)\n",
    "    \n",
    "    loop_counter += 1\n",
    "\n",
    "    if loop_counter % 5 == 0 and loop_counter != 0: # This takes about 25 seconds ? TTT Should be ~ 30 Secs\n",
    "        table = df_final.to_arrow()\n",
    "        if writer is None:\n",
    "            #writer = pq.ParquetWriter(ptk+'\\\\LAX_DN.parquet', table.schema)\n",
    "            writer = pq.ParquetWriter(f's3://{bucket}/{ptk}LAX_DN.parquet', table.schema)\n",
    "        writer.write_table(table)\n",
    "        del table\n",
    "        gc.collect()\n",
    "        df_final = pl.DataFrame() # Reset df_final after writing to file\n",
    "\n",
    "    \n",
    "\n",
    "# Write any remaining chunks to the Parquet file\n",
    "if len(df_final) > 0:\n",
    "    table = df_final.to_arrow()\n",
    "    if writer is None: \n",
    "        writer = pq.ParquetWriter(f's3://{bucket}/{ptk}LAX_DN.parquet', table.schema)\n",
    "    writer.write_table(table)\n",
    "    del table\n",
    "    gc.collect()\n",
    " \n",
    "# Close the ParquetWriter\n",
    "if writer is not None:\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fd398cb-6f31-44c4-9d21-20eb08f7425b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To DO -\n",
    "# QC , Fix Column Sequence [make it numerical for all plantrak codes for both lax_n and _dn]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
