{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89884d06-776e-43a7-8959-422c105bd936",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5266b8b-bc08-4717-9288-e8d58d89da1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import s3fs\n",
    "import boto3\n",
    "from io import BytesIO as bo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb25029-bbe4-477f-8a30-fdaccdc08851",
   "metadata": {},
   "source": [
    "Calculate Date Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b4af2d0-fa4c-45de-9193-7158d9055922",
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables -\n",
    "this_day = datetime.today()\n",
    "# ### FOR TESTING - REMOVE LATER ### \n",
    "this_day = this_day - timedelta(days=7)\n",
    "# ####\n",
    "days_to_monday = (this_day.weekday() - 0) % 7\n",
    "monday = this_day - timedelta(days=days_to_monday)\n",
    "\n",
    "CUR_PROC_WK = monday.strftime(\"%Y%m%d\")\n",
    "\n",
    "CUR_WK0 = monday - timedelta(days=17)\n",
    "CUR_WK = str(CUR_WK0.year) + str(CUR_WK0.month).zfill(2) + str(CUR_WK0.day).zfill(2)\n",
    "QTR = f'{this_day.year}Q{(this_day.month-1)//3+1}'\n",
    "\n",
    "XPN_D = CUR_WK[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f840844-c431-4496-aef0-57a9aeedd4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing IW Release File \n",
    "s3 = s3fs.S3FileSystem()\n",
    "bucket_list = s3.listdir(f'vortex-staging-a65ced90/PYADM/raw/{CUR_PROC_WK}/inbound/')\n",
    "for file in bucket_list:\n",
    "    if (file['Key'].__contains__(f\"IRWD_RELEASE_WKLY_{CUR_PROC_WK}\")):\n",
    "        release_file = file['Key']\n",
    "\n",
    "# Reading Release File -\n",
    "s3_client = boto3.client('s3')\n",
    "bucket = release_file.split('/')[0]\n",
    "file_key = release_file.split('/',1)[1]\n",
    "\n",
    "adm = pd.read_csv(f's3://{bucket}/{file_key}',sep='|')\n",
    "adm1 = adm[CUR_PROC_WK].tolist()\n",
    "\n",
    "for item in adm1:\n",
    "    if item.startswith('P_OUT_110_CUST-DECILE_'):\n",
    "        DECILE_TIMESTAMP = item.split('_')[-1].split('.')[0]\n",
    "    elif item.startswith('P_OUT_110_CUST-TARGET_'):\n",
    "        TARGET_TIMESTAMP = item.split('_')[-1].split('.')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7f4960-f583-4d85-ba21-8aa057027114",
   "metadata": {},
   "source": [
    "Libraries and Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f389bf4-aa61-470b-8ee2-68e273ca6a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIBNAMES\n",
    "raw_path = f'PYADM/raw/{CUR_PROC_WK}/inbound/'\n",
    "staging = 'PYADM/weekly/staging/reference/'\n",
    "ag = f'PYADM/quaterly/{QTR}/target/post/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a21221c-4b18-4d12-bd7e-995a7ceabe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Raw Data (Consider reading in polars to begin with ? may save a few micro seconds)\n",
    "\n",
    "CUST_DECILE = pd.read_csv(\n",
    "    f's3://{bucket}/{raw_path}P_OUT_110_CUST-DECILE_{DECILE_TIMESTAMP}.TXT',delimiter='|',dtype={1:str,2:str,5:str},parse_dates=[6,7]\n",
    ")\n",
    "#CUST_DECILE['DecileID'] = CUST_DECILE['DecileID'].fillna(\"\") #Consider Removing this to save space long term  ? (None takes less space than \"\")\n",
    "CUST_TARGET = pd.read_csv(\n",
    "    f's3://{bucket}/{raw_path}P_OUT_110_CUST-TARGET_{TARGET_TIMESTAMP}.TXT',delimiter='|',dtype={1:str,9:str},parse_dates=[7,8]\n",
    ")\n",
    "\n",
    "#CUST_TARGET[['TargetID', 'TargetFlagValue']] = CUST_TARGET[['TargetID', 'TargetFlagValue']].fillna(\"\")\n",
    "\n",
    "# Converting to polars for faster Operations  - \n",
    "CUST_DECILE = pl.from_pandas(CUST_DECILE)\n",
    "CUST_TARGET = pl.from_pandas(CUST_TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db42163f-0b31-4ea4-9f3d-cd0a7dcc6c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DECILE_TARGET = CUST_DECILE.join(CUST_TARGET,on='IID',how='left')\n",
    "#Note nobs increased after left join , one to many relation posible\n",
    "\n",
    "# Exporting -\n",
    "#DECILE_TARGET.write_parquet(staging+'\\\\target_decile_'+XPN_D+'.parquet',compression='zstd',compression_level=10,use_pyarrow=True)\n",
    "DECILE_TARGET.to_pandas().to_parquet(f's3://{bucket}/{staging}target_decile_{XPN_D}.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cb2e91-d140-4c38-8414-b5339a228366",
   "metadata": {},
   "source": [
    "### Abbvie Targets Code -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "733fa355-c4d1-4dbf-a943-1dc5bd3b2318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 2)\n",
      "┌──────────────────┬─────────┐\n",
      "│ TargetName       ┆ len     │\n",
      "│ ---              ┆ ---     │\n",
      "│ str              ┆ u32     │\n",
      "╞══════════════════╪═════════╡\n",
      "│ LINZESS          ┆ 13112   │\n",
      "│ FRX Sales Target ┆ 36069   │\n",
      "│ null             ┆ 1697491 │\n",
      "└──────────────────┴─────────┘\n"
     ]
    }
   ],
   "source": [
    "print(DECILE_TARGET.group_by('TargetName').len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1388d52a-20c3-4cd3-9e37-534f8d3235d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TD = DECILE_TARGET.filter(pl.col('TargetName')=='FRX Sales Target')\n",
    "\n",
    "if (TD.shape[0] != 0):\n",
    "    TD = TD.sort('IID')\n",
    "    #TD.write_parquet(ag+'\\\\ABBVIE_TARGET.parquet',compression='zstd',compression_level=10,use_pyarrow=True)\n",
    "    TD.to_pandas().to_parquet(f's3://{bucket}/{ag}ABBVIE_TARGET.parquet',compression='snappy')\n",
    "else:\n",
    "    print('Not Exporting since no new FRX Sales Target')\n",
    "    \n",
    "#Not adding export to bit location as it might exist after transition - 'U:\\Ironwood\\projects\\BIT\\2023Q4TargetPost'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
